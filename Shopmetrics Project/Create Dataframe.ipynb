{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b778c75a",
   "metadata": {},
   "source": [
    "### Load Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363a03be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys: ['manifest', 'schema', 'data']\n",
      "\n",
      "SurveyFormElements sample (first 1):\n",
      "[{'uuid': 'ac69a3a5-db77-4cee-af8f-1dfc8975cf32', 'fields': {'SurveyFormID': 28316, 'ElementID': 397320, 'ElementTypeID': 'Q ', 'ObjectName': None, 'Text': \"<p>Please note that the questionnaire is not as long as it seems - multiple questions will be hidden based on your scenario.</p><p>Please read the guidelines below before filling in the questionnaire.\\xa0<br><br>1. Read the questions carefully before answering to understand what exactly it is asking you;<br>2. Your feedback should describe in detail how you felt during the visit/interaction with the Advisor;<br>3. The Advisor's performance is the focus of this questionnaire, not prices, products, or store location;<br>4. Please share constructive feedback on what can be controlled by the Advisor and what s/he could have done to enhance your experience;<br>5. Use the designation used in the question (Associate, Brand Ambassador, Advisor, etc.); Do not use her/his name unless it is precisely asked. Use the correct gender when referring to the Advisor in the comments.<br>6. For each question, the selected answer and comment should be consistent;<br>7. Use the past tense and a rich vocabulary, pay attention to the spelling and punctuation. Avoid incomplete sentences, familiar language, acronyms, or smileys!<br><br>Should you not respect these guidelines, we may deduct up to 30% of your compensation.</p>\", 'Position': 1, 'ParentElementID': None, 'SectionLevel1ParentElementID': None, 'SectionLevel2ParentElementID': None, 'SectionLevel3ParentElementID': None}}]\n",
      "\n",
      "SurveyFormQuestionAnswers sample (first 3):\n",
      "[{'uuid': 'a559f87f-b3f8-4e11-aeaf-c1ea8e0d987e', 'fields': {'SurveyFormID': 28316, 'QuestionID': 358573, 'AnswerSetID': 86108, 'ObjectName': None, 'Position': 1, 'Text': 'Yes', 'Measure': None}}, {'uuid': '7764d993-510e-450b-b4ed-b48481bd4f5f', 'fields': {'SurveyFormID': 28316, 'QuestionID': 358573, 'AnswerSetID': 86108, 'ObjectName': None, 'Position': 2, 'Text': '\\u200bNo\\u200b', 'Measure': None}}, {'uuid': 'f714d1db-3530-43b2-8977-c7e99f38587c', 'fields': {'SurveyFormID': 28316, 'QuestionID': 360187, 'AnswerSetID': 86823, 'ObjectName': None, 'Position': 1, 'Text': 'Africa', 'Measure': None}}]\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "# Load one survey instance\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "with open(\"data_raw/SurveyFormStructureElements_28316.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    survey_structure = json.load(f)\n",
    "\n",
    "# Sanity check: see what top-level keys and sample elements look like\n",
    "print(\"Top-level keys:\", list(survey_structure[0].keys()))\n",
    "print(\"\\nSurveyFormElements sample (first 1):\")\n",
    "print(survey_structure[0][\"data\"][\"SurveyFormElements\"][:1])\n",
    "print(\"\\nSurveyFormQuestionAnswers sample (first 3):\")\n",
    "print(survey_structure[0][\"data\"][\"SurveyFormQuestionAnswers\"][:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3617678d",
   "metadata": {},
   "source": [
    "### Extract Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf586f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Questions:\n",
      "397320: <p>Please note that the questionnaire is not as long as it seems - multiple questions will be hidden based on your scenario.</p><p>Please read the guidelines below before filling in the questionnaire. <br><br>1. Read the questions carefully before answering to understand what exactly it is asking you;<br>2. Your feedback should describe in detail how you felt during the visit/interaction with the Advisor;<br>3. The Advisor's performance is the focus of this questionnaire, not prices, products, or store location;<br>4. Please share constructive feedback on what can be controlled by the Advisor and what s/he could have done to enhance your experience;<br>5. Use the designation used in the question (Associate, Brand Ambassador, Advisor, etc.); Do not use her/his name unless it is precisely asked. Use the correct gender when referring to the Advisor in the comments.<br>6. For each question, the selected answer and comment should be consistent;<br>7. Use the past tense and a rich vocabulary, pay attention to the spelling and punctuation. Avoid incomplete sentences, familiar language, acronyms, or smileys!<br><br>Should you not respect these guidelines, we may deduct up to 30% of your compensation.</p>\n",
      "391189: What was your scenario?\n",
      "391222: Based on your experience on the website, to which extent would you say:<br>“I felt this experience increased my interest for the products”\n",
      "\n",
      "Sample Answers:\n",
      "(358573, 1): Yes\n",
      "(358573, 2): ​No​\n",
      "(360187, 1): Africa\n",
      "(360187, 2): America\n",
      "(360187, 3): Australia\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "# Extract all questions (ID and text)\n",
    "#Creates a dictionary:\n",
    "#For each question (QuestionID), saves its text.\n",
    "#For each answer (AnswerSetID + Position), saves answer text.\n",
    "questions = {}\n",
    "for el in survey_structure[0][\"data\"][\"SurveyFormElements\"]:\n",
    "    f = el[\"fields\"]\n",
    "    if f[\"ElementTypeID\"].strip() == \"Q\" and f[\"ElementID\"]:\n",
    "        questions[f[\"ElementID\"]] = f[\"Text\"]\n",
    "\n",
    "answers = {}\n",
    "for ans in survey_structure[0][\"data\"][\"SurveyFormQuestionAnswers\"]:\n",
    "    f = ans[\"fields\"]\n",
    "    qid = f[\"QuestionID\"]\n",
    "    pos = f[\"Position\"]\n",
    "    answers[(qid, pos)] = f[\"Text\"]\n",
    "\n",
    "print(\"Sample Questions:\")\n",
    "for k, v in list(questions.items())[:3]:\n",
    "    print(f\"{k}: {v}\")\n",
    "print(\"\\nSample Answers:\")\n",
    "for k, v in list(answers.items())[:5]:\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348a12d5",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922ac9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in data: ['QuestionComments', 'QuestionAnswers', 'CustomProperties']\n",
      "\n",
      "Key: QuestionComments - #items: 10000\n",
      "Sample: [{'uuid': 'ed488708-5efa-4254-9c56-cd3db576beff', 'fields': {'SurveyInstanceID': 3009453, 'QuestionID': 405576, 'QuestionObjectName': None, 'Comment': '-'}}, {'uuid': '8cfd648b-e436-4012-91c1-c56eda4c6105', 'fields': {'SurveyInstanceID': 3009554, 'QuestionID': 405979, 'QuestionObjectName': None, 'Comment': '-'}}]\n",
      "\n",
      "Key: QuestionAnswers - #items: 228761\n",
      "Sample: [{'uuid': '5aaba874-6c2c-4758-b43f-a603293473da', 'fields': {'SurveyInstanceID': 3006383, 'QuestionID': 405552, 'QuestionObjectName': None, 'AnswerPos': 1, 'AnswerObjectName': None, 'AnswerIsOtherComment': None}}, {'uuid': 'b1756232-91b0-4c38-a6c5-de333af5c18f', 'fields': {'SurveyInstanceID': 3006383, 'QuestionID': 405552, 'QuestionObjectName': None, 'AnswerPos': 2, 'AnswerObjectName': None, 'AnswerIsOtherComment': None}}]\n",
      "\n",
      "Key: CustomProperties - #items: 14378\n",
      "Sample: [{'uuid': 'b6aa02d8-a275-472e-9f34-047e9ce1c065', 'fields': {'SurveyInstanceID': 3011538, 'PropertyID': 3733, 'PropertyValue': 'Flagship'}}, {'uuid': '4dc66775-948c-4512-9d89-c26d3081169b', 'fields': {'SurveyInstanceID': 3011538, 'PropertyID': 3753, 'PropertyValue': 'Tokyo - Shinjuku Takashimaya LG'}}]\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#Loads the first response JSON, drills into its data block\n",
    "\n",
    "with open(\"data_raw/SurveyInstanceData_28316.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    responses = json.load(f)\n",
    "\n",
    "# Dig into the actual data structure (should be in responses[0][\"data\"])\n",
    "data = responses[0].get('data', None)\n",
    "if data is not None:\n",
    "    print(\"Keys in data:\", list(data.keys()))\n",
    "    for k in data.keys():\n",
    "        items = data[k]\n",
    "        print(f\"\\nKey: {k} - #items: {len(items) if hasattr(items, '__len__') else 'n/a'}\")\n",
    "        if isinstance(items, list):\n",
    "            print(\"Sample:\", items[:2])\n",
    "else:\n",
    "    print(\"No 'data' key found in first response.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c90f3e",
   "metadata": {},
   "source": [
    "### Find Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae9dec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ElementID</th>\n",
       "      <th>Text</th>\n",
       "      <th>IsMulti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>397320</td>\n",
       "      <td>&lt;p&gt;Please note that the questionnaire is</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>391189</td>\n",
       "      <td>What was your scenario?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>391222</td>\n",
       "      <td>Based on your experience on the website,</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>383785</td>\n",
       "      <td>Please select the main reasons why the w</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>368206</td>\n",
       "      <td>Please select the main reasons why you d</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>358573</td>\n",
       "      <td>Did you book an appointment on the websi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>383198</td>\n",
       "      <td>Based on your appointment booking experi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>391244</td>\n",
       "      <td>Please select the main reasons why you f</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>391245</td>\n",
       "      <td>Please select the main reasons why you d</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>383193</td>\n",
       "      <td>Were you contacted by an Advisor after y</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ElementID                                      Text  IsMulti\n",
       "0     397320  <p>Please note that the questionnaire is    False\n",
       "1     391189                   What was your scenario?    False\n",
       "2     391222  Based on your experience on the website,    False\n",
       "3     383785  Please select the main reasons why the w     True\n",
       "4     368206  Please select the main reasons why you d     True\n",
       "5     358573  Did you book an appointment on the websi    False\n",
       "6     383198  Based on your appointment booking experi    False\n",
       "7     391244  Please select the main reasons why you f     True\n",
       "8     391245  Please select the main reasons why you d     True\n",
       "9     383193  Were you contacted by an Advisor after y     True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "#Builds lookup tables to decide whether each QuestionID allows multiple selections \n",
    "# by marrying QuestionAnswerSetProperties with the answer list\n",
    "answer_sets = survey_structure[0]['data']['QuestionAnswerSetProperties']\n",
    "\n",
    "answer_set_id_to_multiple = {\n",
    "    a['fields']['AnswerSetID']: a['fields'].get('IsMultipleSelection', False)\n",
    "    for a in answer_sets\n",
    "}\n",
    "# Build question_answers: maps QuestionID to list of answer dicts (from survey_structure)\n",
    "question_answers = {}\n",
    "for a in survey_structure[0][\"data\"][\"SurveyFormQuestionAnswers\"]:\n",
    "    qid = a[\"fields\"][\"QuestionID\"]\n",
    "    question_answers.setdefault(qid, []).append(a[\"fields\"])\n",
    "\n",
    "def is_multi(qid):\n",
    "    ans = question_answers.get(qid, [])\n",
    "    if ans:\n",
    "        as_etid = ans[0]['AnswerSetID']\n",
    "        return answer_set_id_to_multiple.get(as_etid, False)\n",
    "    return False\n",
    "\n",
    "# Show if a few questions are multi-select\n",
    "sample = []\n",
    "for qid, qtext in list(questions.items())[:10]:\n",
    "    sample.append({\n",
    "        'ElementID': qid,\n",
    "        'Text': (qtext or '')[:40],\n",
    "        'IsMulti': is_multi(qid)\n",
    "    })\n",
    "pd.DataFrame(sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1149fca5",
   "metadata": {},
   "source": [
    "### Build a minimal \"pivot\" DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ab25db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA fields columns: ['SurveyInstanceID', 'QuestionID', 'QuestionObjectName', 'AnswerPos', 'AnswerObjectName', 'AnswerIsOtherComment']\n",
      "   SurveyInstanceID  QuestionID  QuestionObjectName  AnswerPos  \\\n",
      "0         3006383.0    405552.0                 NaN        1.0   \n",
      "1         3006383.0    405552.0                 NaN        2.0   \n",
      "2         3006383.0    405552.0                 NaN        3.0   \n",
      "3         3006383.0    405552.0                 NaN        4.0   \n",
      "4         3006383.0    405553.0                 NaN        1.0   \n",
      "\n",
      "   AnswerObjectName  AnswerIsOtherComment  \n",
      "0               NaN                   NaN  \n",
      "1               NaN                   NaN  \n",
      "2               NaN                   NaN  \n",
      "3               NaN                   NaN  \n",
      "4               NaN                   NaN  \n",
      "Unique instances: 2054\n",
      "Unique questions: 116\n",
      "Sample AnswerPos: [1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "#5a\n",
    "\n",
    "# Convert QuestionAnswers to a DataFrame\n",
    "\n",
    "qa = pd.DataFrame(data[\"QuestionAnswers\"])\n",
    "# Expand 'fields' dict into columns\n",
    "qa_fields = qa['fields'].apply(pd.Series)\n",
    "\n",
    "# Preview columns and data\n",
    "print(\"QA fields columns:\", qa_fields.columns.tolist())\n",
    "print(qa_fields.head())\n",
    "\n",
    "# Just check how many unique SurveyInstanceID, QuestionID, and AnswerPos we have\n",
    "print(\"Unique instances:\", qa_fields['SurveyInstanceID'].nunique())\n",
    "print(\"Unique questions:\", qa_fields['QuestionID'].nunique())\n",
    "print(\"Sample AnswerPos:\", qa_fields['AnswerPos'].unique()[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbfe1e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot shape: (2054, 696)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col</th>\n",
       "      <th>358573_1</th>\n",
       "      <th>358573_2</th>\n",
       "      <th>360187_1</th>\n",
       "      <th>360187_12</th>\n",
       "      <th>360187_14</th>\n",
       "      <th>360187_15</th>\n",
       "      <th>360187_16</th>\n",
       "      <th>360187_17</th>\n",
       "      <th>360187_18</th>\n",
       "      <th>360187_19</th>\n",
       "      <th>...</th>\n",
       "      <th>406171_2</th>\n",
       "      <th>406171_3</th>\n",
       "      <th>406171_4</th>\n",
       "      <th>406171_5</th>\n",
       "      <th>406171_6</th>\n",
       "      <th>406171_7</th>\n",
       "      <th>406171_8</th>\n",
       "      <th>406181_1</th>\n",
       "      <th>406181_2</th>\n",
       "      <th>406181_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SurveyInstanceID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3005492.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005493.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005494.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005495.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005496.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 696 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col               358573_1  358573_2  360187_1  360187_12  360187_14  \\\n",
       "SurveyInstanceID                                                       \n",
       "3005492.0                1         0         0          0          0   \n",
       "3005493.0                0         0         0          0          0   \n",
       "3005494.0                0         0         0          0          0   \n",
       "3005495.0                0         0         0          0          0   \n",
       "3005496.0                1         0         0          0          0   \n",
       "\n",
       "col               360187_15  360187_16  360187_17  360187_18  360187_19  ...  \\\n",
       "SurveyInstanceID                                                         ...   \n",
       "3005492.0                 0          0          0          0          0  ...   \n",
       "3005493.0                 0          0          0          0          0  ...   \n",
       "3005494.0                 0          0          0          0          0  ...   \n",
       "3005495.0                 0          0          0          0          0  ...   \n",
       "3005496.0                 0          0          0          0          0  ...   \n",
       "\n",
       "col               406171_2  406171_3  406171_4  406171_5  406171_6  406171_7  \\\n",
       "SurveyInstanceID                                                               \n",
       "3005492.0                0         0         0         0         0         0   \n",
       "3005493.0                0         0         0         0         0         0   \n",
       "3005494.0                1         0         0         0         0         0   \n",
       "3005495.0                0         0         0         0         0         0   \n",
       "3005496.0                0         0         0         0         0         0   \n",
       "\n",
       "col               406171_8  406181_1  406181_2  406181_3  \n",
       "SurveyInstanceID                                          \n",
       "3005492.0                0         0         0         1  \n",
       "3005493.0                0         0         0         1  \n",
       "3005494.0                0         0         0         1  \n",
       "3005495.0                0         0         0         1  \n",
       "3005496.0                0         1         0         0  \n",
       "\n",
       "[5 rows x 696 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5b\n",
    "# Create a column for pivot: QuestionID_AnswerPos\n",
    "qa_fields['col'] = qa_fields['QuestionID'].astype(int).astype(str) + \"_\" + qa_fields['AnswerPos'].astype(int).astype(str)\n",
    "qa_fields['value'] = 1\n",
    "\n",
    "# Pivot to wide (one-hot) format\n",
    "pivot = qa_fields.pivot_table(index=\"SurveyInstanceID\", columns=\"col\", values=\"value\", fill_value=0, aggfunc=\"max\")\n",
    "\n",
    "print(\"Pivot shape:\", pivot.shape)\n",
    "display(pivot.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9668c",
   "metadata": {},
   "source": [
    "### Collapse 2 Answer Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba7bfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 10 columns from binary questions.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col</th>\n",
       "      <th>358573_1</th>\n",
       "      <th>360187_1</th>\n",
       "      <th>360187_12</th>\n",
       "      <th>360187_14</th>\n",
       "      <th>360187_15</th>\n",
       "      <th>360187_16</th>\n",
       "      <th>360187_17</th>\n",
       "      <th>360187_18</th>\n",
       "      <th>360187_19</th>\n",
       "      <th>360187_2</th>\n",
       "      <th>...</th>\n",
       "      <th>406171_2</th>\n",
       "      <th>406171_3</th>\n",
       "      <th>406171_4</th>\n",
       "      <th>406171_5</th>\n",
       "      <th>406171_6</th>\n",
       "      <th>406171_7</th>\n",
       "      <th>406171_8</th>\n",
       "      <th>406181_1</th>\n",
       "      <th>406181_2</th>\n",
       "      <th>406181_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SurveyInstanceID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3005492.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005493.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005494.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005495.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005496.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 686 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col               358573_1  360187_1  360187_12  360187_14  360187_15  \\\n",
       "SurveyInstanceID                                                        \n",
       "3005492.0                1         0          0          0          0   \n",
       "3005493.0                0         0          0          0          0   \n",
       "3005494.0                0         0          0          0          0   \n",
       "3005495.0                0         0          0          0          0   \n",
       "3005496.0                1         0          0          0          0   \n",
       "\n",
       "col               360187_16  360187_17  360187_18  360187_19  360187_2  ...  \\\n",
       "SurveyInstanceID                                                        ...   \n",
       "3005492.0                 0          0          0          0         0  ...   \n",
       "3005493.0                 0          0          0          0         0  ...   \n",
       "3005494.0                 0          0          0          0         0  ...   \n",
       "3005495.0                 0          0          0          0         0  ...   \n",
       "3005496.0                 0          0          0          0         0  ...   \n",
       "\n",
       "col               406171_2  406171_3  406171_4  406171_5  406171_6  406171_7  \\\n",
       "SurveyInstanceID                                                               \n",
       "3005492.0                0         0         0         0         0         0   \n",
       "3005493.0                0         0         0         0         0         0   \n",
       "3005494.0                1         0         0         0         0         0   \n",
       "3005495.0                0         0         0         0         0         0   \n",
       "3005496.0                0         0         0         0         0         0   \n",
       "\n",
       "col               406171_8  406181_1  406181_2  406181_3  \n",
       "SurveyInstanceID                                          \n",
       "3005492.0                0         0         0         1  \n",
       "3005493.0                0         0         0         1  \n",
       "3005494.0                0         0         0         1  \n",
       "3005495.0                0         0         0         1  \n",
       "3005496.0                0         1         0         0  \n",
       "\n",
       "[5 rows x 686 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6\n",
    "# Collapse 2-option questions to a single column \n",
    "\n",
    "# Helper to recognise a \"no/negative\" answer label\n",
    "def looks_like_no(txt):\n",
    "    return str(txt).strip().lower() in {\"no\", \"none\", \"n/a\", \"na\", \"false\", \"0\", \"nope\"}\n",
    "\n",
    "cols_to_drop = []\n",
    "\n",
    "# Group current wide columns by QuestionID (prefix before the underscore)\n",
    "from collections import defaultdict\n",
    "qid_to_cols = defaultdict(list)\n",
    "for col in pivot.columns:\n",
    "    qid, pos = col.split(\"_\", 1)\n",
    "    qid_to_cols[qid].append((int(pos), col))\n",
    "\n",
    "for qid, pos_col_list in qid_to_cols.items():\n",
    "    # Only care about questions that produced exactly two columns\n",
    "    if len(pos_col_list) == 2:\n",
    "        pos_col_list.sort()  # sort by AnswerPos for determinism\n",
    "        (pos1, col1), (pos2, col2) = pos_col_list\n",
    "\n",
    "        # Try to read the answer labels from the dict you built earlier\n",
    "        label1 = answers.get((int(qid), pos1), \"\")\n",
    "        label2 = answers.get((int(qid), pos2), \"\")\n",
    "\n",
    "        # Prefer to drop the column whose label looks like \"No\"\n",
    "        if looks_like_no(label1):\n",
    "            drop_col = col1\n",
    "        elif looks_like_no(label2):\n",
    "            drop_col = col2\n",
    "        else:\n",
    "            # Fallback: drop the one that is \"mostly zeros\" (lower mean of 1s)\n",
    "            mean1 = pivot[col1].mean()\n",
    "            mean2 = pivot[col2].mean()\n",
    "            drop_col = col1 if mean1 < mean2 else col2\n",
    "\n",
    "        cols_to_drop.append(drop_col)\n",
    "\n",
    "# Actually drop them and keep going with the same variable name (`pivot`)\n",
    "pivot = pivot.drop(columns=cols_to_drop)\n",
    "\n",
    "print(f\"Dropped {len(cols_to_drop)} columns from binary questions.\")\n",
    "pivot.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639651c",
   "metadata": {},
   "source": [
    "### Dataframe Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cd51051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns: 536\n",
      "[\"397320: <p>Please note that the questionnaire is not as long as it seems - multiple questions will be hidden based on your scenario.</p><p>Please read the guidelines below before filling in the questionnaire.\\xa0<br><br>1. Read the questions carefully before answering to understand what exactly it is asking you;<br>2. Your feedback should describe in detail how you felt during the visit/interaction with the Advisor;<br>3. The Advisor's performance is the focus of this questionnaire, not prices, products, or store location;<br>4. Please share constructive feedback on what can be controlled by the Advisor and what s/he could have done to enhance your experience;<br>5. Use the designation used in the question (Associate, Brand Ambassador, Advisor, etc.); Do not use her/his name unless it is precisely asked. Use the correct gender when referring to the Advisor in the comments.<br>6. For each question, the selected answer and comment should be consistent;<br>7. Use the past tense and a rich vocabulary, pay attention to the spelling and punctuation. Avoid incomplete sentences, familiar language, acronyms, or smileys!<br><br>Should you not respect these guidelines, we may deduct up to 30% of your compensation.</p>\", '391189: What was your scenario?', '391222: Based on your experience on the website, to which extent would you say:<br>“I felt this experience increased my interest for the products”', '383785_1: The product display (number of photos and different angles, with product worn by mannequin, zoom available)', '383785_2: The product description', '383785_3: The product story telling (origin, inspiration, sustainability, legacy of the product)', '383785_4: The ways of visualizing the products (tutorials, virtual try-on, 3D visual, etc.)', '383785_5: The product availability information', '383785_6: The product price (readily available)', '383785_7: The website provided the right amount of relevant information', '383785_8: Other, please specify', '368206_1: The product display (number of photos and different angles, with product worn by mannequin, zoom available)', '368206_2: The product description', '368206_3: The lack of product story telling (origin, inspiration, sustainability, legacy of the product)', '368206_4: The lack of ways of visualizing the product (tutorials, virtual try-on, 3D visual, etc.)']\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "#generates a full list of readable DataFrame column names, using the survey structure\n",
    "\n",
    "\n",
    "# Setup: build a lookup for which AnswerSetIDs are multi-select\n",
    "answer_sets = survey_structure[0][\"data\"][\"QuestionAnswerSetProperties\"]\n",
    "answer_set_id_to_multiple = {\n",
    "    a['fields']['AnswerSetID']: a['fields'].get('IsMultipleSelection', False)\n",
    "    for a in answer_sets\n",
    "}\n",
    "\n",
    "# Build: map each QuestionID to its AnswerSetID (from structure)\n",
    "qid_to_asid = {}\n",
    "for ans in survey_structure[0][\"data\"][\"SurveyFormQuestionAnswers\"]:\n",
    "    f = ans[\"fields\"]\n",
    "    qid = f[\"QuestionID\"]\n",
    "    asid = f[\"AnswerSetID\"]\n",
    "    qid_to_asid[qid] = asid\n",
    "\n",
    "def is_multi(qid):\n",
    "    asid = qid_to_asid.get(qid)\n",
    "    return answer_set_id_to_multiple.get(asid, False)\n",
    "\n",
    "# Now generate readable columns for the pivot table\n",
    "columns = []\n",
    "for qid in questions:\n",
    "    ans = [a for (qid2, pos), a in answers.items() if qid2 == qid]\n",
    "    if ans and is_multi(qid):\n",
    "        for pos in range(1, len(ans)+1):\n",
    "            label = answers.get((qid, pos), f\"Ans{pos}\")\n",
    "            label = str(label).replace('\\n', ' ').replace('\\r', ' ')\n",
    "            columns.append(f\"{qid}_{pos}: {label}\")\n",
    "    else:\n",
    "        columns.append(f\"{qid}: {questions[qid]}\")\n",
    "        \n",
    "print(f\"Total columns: {len(columns)}\")\n",
    "print(columns[:15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a0201f",
   "metadata": {},
   "source": [
    "### Produce DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6577e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col</th>\n",
       "      <th>SurveyInstanceID</th>\n",
       "      <th>358573_1</th>\n",
       "      <th>360187_1</th>\n",
       "      <th>360187_12</th>\n",
       "      <th>360187_14</th>\n",
       "      <th>360187_15</th>\n",
       "      <th>360187_16</th>\n",
       "      <th>360187_17</th>\n",
       "      <th>360187_18</th>\n",
       "      <th>360187_19</th>\n",
       "      <th>...</th>\n",
       "      <th>406171_2</th>\n",
       "      <th>406171_3</th>\n",
       "      <th>406171_4</th>\n",
       "      <th>406171_5</th>\n",
       "      <th>406171_6</th>\n",
       "      <th>406171_7</th>\n",
       "      <th>406171_8</th>\n",
       "      <th>406181_1</th>\n",
       "      <th>406181_2</th>\n",
       "      <th>406181_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3005492.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3005493.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3005494.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3005495.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3005496.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 687 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col  SurveyInstanceID  358573_1  360187_1  360187_12  360187_14  360187_15  \\\n",
       "0           3005492.0         1         0          0          0          0   \n",
       "1           3005493.0         0         0          0          0          0   \n",
       "2           3005494.0         0         0          0          0          0   \n",
       "3           3005495.0         0         0          0          0          0   \n",
       "4           3005496.0         1         0          0          0          0   \n",
       "\n",
       "col  360187_16  360187_17  360187_18  360187_19  ...  406171_2  406171_3  \\\n",
       "0            0          0          0          0  ...         0         0   \n",
       "1            0          0          0          0  ...         0         0   \n",
       "2            0          0          0          0  ...         1         0   \n",
       "3            0          0          0          0  ...         0         0   \n",
       "4            0          0          0          0  ...         0         0   \n",
       "\n",
       "col  406171_4  406171_5  406171_6  406171_7  406171_8  406181_1  406181_2  \\\n",
       "0           0         0         0         0         0         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         0         0   \n",
       "4           0         0         0         0         0         1         0   \n",
       "\n",
       "col  406181_3  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 687 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8 ── Keep column names strictly as IDs  ──────────────────────────────────────\n",
    "# (e.g. \"405982_3\", without the \": All questions were clear …\" suffix)\n",
    "\n",
    "# Build a mapping that strips anything following the first colon, if present.\n",
    "pretty_map = {col: col.split(\":\", 1)[0] for col in pivot.columns}\n",
    "\n",
    "# Apply mapping and make SurveyInstanceID a normal column\n",
    "pivot_pretty = (\n",
    "    pivot\n",
    "      .rename(columns=pretty_map)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Quick preview\n",
    "display(pivot_pretty.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b607a",
   "metadata": {},
   "source": [
    "### Adding Total 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "283b96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8A ── Convert free-text “Other” answers → binary flags\n",
    "import re\n",
    "\n",
    "source_df = pivot_pretty          # this dataframe exists already\n",
    "\n",
    "# 1) columns that look like free-text “Other”\n",
    "other_text_cols = [\n",
    "    c for c in source_df.columns\n",
    "    if re.search(r'other', c, flags=re.I) and source_df[c].dtype == \"object\"\n",
    "]\n",
    "\n",
    "# 2) create <QuestionID>_other flags (1 = respondent typed something)\n",
    "for col in other_text_cols:\n",
    "    qid_match = re.match(r\"(\\d+)\", col)      # grab the numeric QuestionID\n",
    "    if not qid_match:\n",
    "        continue\n",
    "    qid = qid_match.group(1)\n",
    "    pivot_pretty[f\"{qid}_other\"] = source_df[col].notna().astype(\"Int8\")\n",
    "\n",
    "# 3) drop the raw free-text columns\n",
    "pivot_pretty = pivot_pretty.drop(columns=other_text_cols, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b686e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 8B ── Close any numeric gaps in answer-position columns\n",
    "# #       Example: 383785_1 … 383785_7 383785_9  →  383785_1 … 383785_7 383785_8\n",
    "# #       The free-text “Other” checkbox (if present as *_other or *_11) becomes\n",
    "# #       the next index after the last numeric option.\n",
    "\n",
    "# import re\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # 1) collect numeric positions and any “Other” column per question\n",
    "# qid_numeric = defaultdict(list)   # {qid: [pos, pos, …]}\n",
    "# qid_other   = {}                  # {qid: 'col_name_marking_other'}\n",
    "\n",
    "# for col in pivot_pretty.columns:\n",
    "#     m_num  = re.match(r'^(\\d+)_(\\d+)$', col)        # e.g. 383785_9\n",
    "#     m_oth  = re.match(r'^(\\d+)_other$', col)        # e.g. 383785_other\n",
    "#     m_11   = re.match(r'^(\\d+)_11$',   col)         # e.g. 383785_11  (often Other)\n",
    "\n",
    "#     if m_num:\n",
    "#         qid, pos = m_num.groups()\n",
    "#         qid_numeric[qid].append(int(pos))\n",
    "#     elif m_oth:\n",
    "#         qid_other[m_oth.group(1)] = col\n",
    "#     elif m_11:                                      # treat *_11 as “Other”\n",
    "#         qid_other[m_11.group(1)] = col\n",
    "\n",
    "# # 2) build a rename-map so numeric indices become consecutive 1…N\n",
    "# rename_map = {}\n",
    "\n",
    "# for qid, positions in qid_numeric.items():\n",
    "#     positions_sorted = sorted(set(positions))\n",
    "#     for new_idx, old_idx in enumerate(positions_sorted, start=1):\n",
    "#         old_name = f\"{qid}_{old_idx}\"\n",
    "#         new_name = f\"{qid}_{new_idx}\"\n",
    "#         if old_name != new_name:\n",
    "#             rename_map[old_name] = new_name\n",
    "\n",
    "#     # handle “Other” → next sequential index\n",
    "#     if qid in qid_other:\n",
    "#         other_old = qid_other[qid]\n",
    "#         next_idx  = len(positions_sorted) + 1\n",
    "#         new_name  = f\"{qid}_{next_idx}\"\n",
    "#         # if collision (very unlikely) keep incrementing\n",
    "#         while new_name in pivot_pretty.columns:\n",
    "#             next_idx += 1\n",
    "#             new_name = f\"{qid}_{next_idx}\"\n",
    "#         rename_map[other_old] = new_name\n",
    "\n",
    "# # 3) apply renaming\n",
    "# pivot_pretty.rename(columns=rename_map, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "450723c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "# Add a bottom row with % of 1s per column\n",
    "\n",
    "# Work on a copy so you can still inspect the original if needed\n",
    "df_out = pivot_pretty.copy()\n",
    "\n",
    "# Columns that should be checked for 1s (exclude IDs or text cols)\n",
    "non_binary_cols = ['SurveyInstanceID']  # add more here if needed\n",
    "target_cols = [c for c in df_out.columns if c not in non_binary_cols]\n",
    "\n",
    "# Compute % of 1s\n",
    "pct_ones = (df_out[target_cols].eq(1).sum() / len(df_out)) * 100\n",
    "\n",
    "# Build the summary row\n",
    "summary_row = pd.Series(index=df_out.columns, dtype='object')\n",
    "summary_row[target_cols] = pct_ones.round(2)\n",
    "summary_row[non_binary_cols] = 'Pct_1s'   # label cell(s) so you can spot the row\n",
    "\n",
    "# Append to the bottom\n",
    "df_out = pd.concat([df_out, summary_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "# If you want downstream cells (e.g., export) to use it:\n",
    "pivot_pretty = df_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b1546",
   "metadata": {},
   "source": [
    "### Merging Data Low Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eabb9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 columns were merged into new low-frequency buckets.\n",
      "Example new bucket(s): ['360187_24', '360190_4', '368206_9', '369184_6', '369188_6']\n"
     ]
    }
   ],
   "source": [
    "# 10 \n",
    "# Collapse rare answers (<5%) into “Other” buckets, but ignore Likert cols\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# ── 0) List of all 16 Likert base IDs to skip ───────────────────────────────\n",
    "LIKERT_BASE_IDS = {\n",
    "    \"391222\",\"383198\",\"383199\",\"391201\",\"391213\",\n",
    "    \"380319\",\"380514\",\"405548\",\"383195\",\"380437\",\n",
    "    \"397317\",\"380448\",\"380442\",\"405583\",\"405568\",\"405978\"\n",
    "}\n",
    "\n",
    "# ── 1) Remove summary row we added earlier ─────────────────────────────────\n",
    "summary_mask = pivot_pretty['SurveyInstanceID'].eq('Pct_1s')\n",
    "df = pivot_pretty.loc[~summary_mask].copy()\n",
    "\n",
    "# ── 2) Identify candidate columns to examine (exclude ID column) ────────────\n",
    "non_binary_cols = ['SurveyInstanceID']\n",
    "target_cols     = [c for c in df.columns if c not in non_binary_cols]\n",
    "\n",
    "# ── 3) Compute % of 1s per column; find columns under 5% (and non-Likert) ──\n",
    "pct_ones = df[target_cols].eq(1).mean() * 100\n",
    "\n",
    "def split_col(col):\n",
    "    head = col.split(':', 1)[0]\n",
    "    if '_' in head:\n",
    "        qid, pos = head.split('_', 1)\n",
    "        try:\n",
    "            return qid.strip(), int(pos)\n",
    "        except ValueError:\n",
    "            return qid.strip(), None\n",
    "    return head.strip(), None\n",
    "\n",
    "def get_qid(col):\n",
    "    return split_col(col)[0]\n",
    "\n",
    "# Only collapse non-Likert columns whose positive rate is below 5%\n",
    "rare_cols = [\n",
    "    c for c, pct in pct_ones.items()\n",
    "    if pct < 5 and get_qid(c) not in LIKERT_BASE_IDS\n",
    "]\n",
    "\n",
    "# ── 4) Group rare cols by QuestionID ────────────────────────────────────────\n",
    "qid_to_rare = defaultdict(list)\n",
    "for c in rare_cols:\n",
    "    qid_to_rare[get_qid(c)].append(c)\n",
    "\n",
    "# ── 5) Build new “Other” bucket columns ────────────────────────────────────\n",
    "new_cols_data = {}\n",
    "merge_log    = {}\n",
    "merged_count = 0\n",
    "\n",
    "for qid, cols in qid_to_rare.items():\n",
    "    # find existing answer positions for this question\n",
    "    existing_pos = [\n",
    "        split_col(c)[1]\n",
    "        for c in df.columns\n",
    "        if split_col(c)[0] == qid and split_col(c)[1] is not None\n",
    "    ]\n",
    "    next_pos = (max(existing_pos) + 1) if existing_pos else 1\n",
    "\n",
    "    # ensure unique new column name\n",
    "    new_col = f\"{qid}_{next_pos}\"\n",
    "    while new_col in df.columns or new_col in new_cols_data:\n",
    "        next_pos += 1\n",
    "        new_col = f\"{qid}_{next_pos}\"\n",
    "\n",
    "    # collapse: mark 1 if any of the rare columns was chosen\n",
    "    new_cols_data[new_col] = df[cols].any(axis=1).astype(int)\n",
    "    merge_log[new_col]    = cols\n",
    "    merged_count += len(cols)\n",
    "\n",
    "    # if you maintain an answers dict for lookups, label it “Other”\n",
    "    if 'answers' in globals():\n",
    "        answers[(qid, next_pos)] = \"Other\"\n",
    "\n",
    "# ── 6) Apply changes: drop old rare cols, add new buckets ───────────────────\n",
    "others_df = pd.DataFrame(new_cols_data, index=df.index)\n",
    "df = pd.concat([df.drop(columns=rare_cols, errors='ignore'), others_df], axis=1)\n",
    "\n",
    "# ── 7) Rebuild the summary row and reattach it ─────────────────────────────\n",
    "new_target_cols  = [c for c in df.columns if c not in non_binary_cols]\n",
    "new_pct_ones     = (df[new_target_cols].eq(1).mean() * 100).round(2)\n",
    "\n",
    "summary_row = pd.Series(index=df.columns, dtype='object')\n",
    "summary_row[new_target_cols] = new_pct_ones\n",
    "summary_row[non_binary_cols] = 'Pct_1s'\n",
    "\n",
    "pivot_pretty = pd.concat([df, summary_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "print(f\"{merged_count} columns were merged into new low-frequency buckets.\")\n",
    "print(\"Example new bucket(s):\", list(merge_log.keys())[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba809f",
   "metadata": {},
   "source": [
    "##### Data Summary on Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af89f341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall pct of respondents selecting any \"Other\": 83.93%\n",
      "\n",
      "First 5 rows of other_summary:\n",
      "          count_1s     pct_1s     qid  pos  \\\n",
      "360187_24      300  14.605648  360187   24   \n",
      "360190_4        52   2.531646  360190    4   \n",
      "368206_9        63   3.067186  368206    9   \n",
      "369184_6        42   2.044791  369184    6   \n",
      "369188_6        94   4.576436  369188    6   \n",
      "\n",
      "                                               question_text answer_text  \\\n",
      "360187_24                           Which area are you from?       Other   \n",
      "360190_4                                          Are you a:       Other   \n",
      "368206_9   Please select the main reasons why you did not...       Other   \n",
      "369184_6   Based on your journey across these different t...       Other   \n",
      "369188_6   Based on your experience, to which extent woul...       Other   \n",
      "\n",
      "                                                 merged_from  merged_n  \n",
      "360187_24  [360187_1, 360187_12, 360187_14, 360187_15, 36...        19  \n",
      "360190_4                                          [360190_3]         1  \n",
      "368206_9   [368206_1, 368206_2, 368206_3, 368206_4, 36820...         8  \n",
      "369184_6                                [369184_4, 369184_5]         2  \n",
      "369188_6                                [369188_4, 369188_5]         2  \n",
      "\n",
      "First 5 rows of by_question:\n",
      "qid\n",
      "360187    14.605648\n",
      "360190     2.531646\n",
      "368206     3.067186\n",
      "369184     2.044791\n",
      "369188     4.576436\n",
      "Name: pct_other, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 11a\n",
    "#  Summary of \"% Other\" buckets (robust, no .str.split)\n",
    "\n",
    "summary_mask = pivot_pretty['SurveyInstanceID'].eq('Pct_1s')\n",
    "df_only      = pivot_pretty.loc[~summary_mask]\n",
    "\n",
    "# All \"Other\" columns created in #10a\n",
    "other_cols = list(merge_log.keys())\n",
    "\n",
    "n_rows = len(df_only)\n",
    "\n",
    "# Counts & % for each \"_Other\" bucket column\n",
    "counts = df_only[other_cols].sum()\n",
    "\n",
    "other_summary = counts.to_frame('count_1s')\n",
    "other_summary['pct_1s'] = (other_summary['count_1s'] / n_rows * 100).round(2)\n",
    "\n",
    "def parse_qid_pos(col):\n",
    "    head = col.split(':', 1)[0]          # strip pretty text if present\n",
    "    parts = head.split('_', 1)\n",
    "    qid = parts[0]\n",
    "    pos = int(parts[1]) if len(parts) > 1 and parts[1].isdigit() else None\n",
    "    return qid, pos\n",
    "\n",
    "qid_pos = [parse_qid_pos(c) for c in other_summary.index]\n",
    "other_summary['qid'] = [q for q, p in qid_pos]\n",
    "other_summary['pos'] = [p for q, p in qid_pos]\n",
    "\n",
    "# Question text and label\n",
    "other_summary['question_text'] = other_summary['qid'].map(\n",
    "    lambda q: questions.get(int(q), questions.get(q, '[Question not found]'))\n",
    ")\n",
    "other_summary['answer_text']   = 'Other'\n",
    "\n",
    "# What was merged\n",
    "other_summary['merged_from'] = other_summary.index.map(lambda c: merge_log.get(c, []))\n",
    "other_summary['merged_n']    = other_summary['merged_from'].str.len()\n",
    "\n",
    "# % \"Other\" per question (combine if multiple buckets)\n",
    "by_question = (\n",
    "    other_summary.groupby('qid')['count_1s'].sum() / n_rows * 100\n",
    ").round(2).rename('pct_other')\n",
    "\n",
    "# Overall % of respondents who hit ANY \"Other\"\n",
    "overall_other_pct = (df_only[other_cols].any(axis=1).mean() * 100).round(2)\n",
    "\n",
    "print(f'Overall pct of respondents selecting any \"Other\": {overall_other_pct}%')\n",
    "print('\\nFirst 5 rows of other_summary:')\n",
    "print(other_summary.head())\n",
    "print('\\nFirst 5 rows of by_question:')\n",
    "print(by_question.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49216b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summaries to data_processed/other_summaries.xlsx\n"
     ]
    }
   ],
   "source": [
    "# 11b\n",
    "# Save the newly calculated summaries to /data_processed\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"data_processed\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Tidy up frames for writing\n",
    "other_summary_out = other_summary.reset_index().rename(columns={'index': 'col_name'})\n",
    "by_question_out   = by_question.reset_index().rename(columns={'qid': 'QuestionID'})\n",
    "\n",
    "merge_log_out = pd.DataFrame(\n",
    "    [(k, v) for k, v in merge_log.items()],\n",
    "    columns=['new_col', 'merged_from']\n",
    ")\n",
    "\n",
    "# Option A: separate workbook just for summaries\n",
    "with pd.ExcelWriter(out_dir / \"other_summaries.xlsx\", engine=\"openpyxl\") as w:\n",
    "    other_summary_out.to_excel(w, sheet_name=\"other_cols\", index=False)\n",
    "    by_question_out.to_excel(w, sheet_name=\"pct_other_by_qid\", index=False)\n",
    "    merge_log_out.to_excel(w, sheet_name=\"merge_log\", index=False)\n",
    "\n",
    "# Option B (commented): append as sheets to your existing export\n",
    "# with pd.ExcelWriter(out_dir / \"survey_dataframe.xlsx\",\n",
    "#                     engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as w:\n",
    "#     other_summary_out.to_excel(w, sheet_name=\"other_cols\", index=False)\n",
    "#     by_question_out.to_excel(w, sheet_name=\"pct_other_by_qid\", index=False)\n",
    "#     merge_log_out.to_excel(w, sheet_name=\"merge_log\", index=False)\n",
    "\n",
    "print(\"Saved summaries to data_processed/other_summaries.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e9b56",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13e7000d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of answers_list: <class 'list'>\n",
      "Number of answer records: 228761\n",
      "Keys in first answer record: ['uuid', 'fields']\n",
      "Sample of first answer record:\n",
      " {'uuid': '5aaba874-6c2c-4758-b43f-a603293473da', 'fields': {'SurveyInstanceID': 3006383, 'QuestionID': 405552, 'QuestionObjectName': None, 'AnswerPos': 1, 'AnswerObjectName': None, 'AnswerIsOtherComment': None}}\n"
     ]
    }
   ],
   "source": [
    "# 12\n",
    "# Load instance data and drill down to actual list of answers\n",
    "\n",
    "with open('data_raw/SurveyInstanceData_28316.json', 'r', encoding='utf-8') as f:\n",
    "    instance_data = json.load(f)\n",
    "\n",
    "# Navigate: list -> dict ('data') -> dict (with 'QuestionAnswers') -> the giant list\n",
    "answers_list = instance_data[0]['data']['QuestionAnswers']\n",
    "\n",
    "print(\"Type of answers_list:\", type(answers_list))\n",
    "print(\"Number of answer records:\", len(answers_list))\n",
    "print(\"Keys in first answer record:\", list(answers_list[0].keys()))\n",
    "print(\"Sample of first answer record:\\n\", answers_list[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d2e838",
   "metadata": {},
   "source": [
    "### Printing Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38cdb4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to survey_dataframe.xlsx\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "\n",
    "pivot_pretty.to_excel(\"data_processed/survey_dataframe.xlsx\", index=False)\n",
    "print(\"Output written to survey_dataframe.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e019c1a2",
   "metadata": {},
   "source": [
    "### Mapping Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3db1e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping sheet written to data_processed\\survey_dataframe.xlsx (sheet name: 'mapping')\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "# Creating a mapping for all the column names on a second sheet\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# --- build mapping dataframe -----------------------------------------------\n",
    "\n",
    "rows = []\n",
    "for col in pivot_pretty.columns:\n",
    "    if col == \"SurveyInstanceID\":\n",
    "        continue                      # skip the identifier column\n",
    "\n",
    "    # Strip any pretty label suffix after \":\"\n",
    "    head = col.split(\":\", 1)[0]\n",
    "\n",
    "    # Parse QuestionID and AnswerPos if present\n",
    "    if \"_\" in head:\n",
    "        qid, pos_str = head.split(\"_\", 1)\n",
    "        try:\n",
    "            pos = int(pos_str)\n",
    "        except ValueError:\n",
    "            pos = None\n",
    "    else:\n",
    "        qid, pos = head, None\n",
    "\n",
    "    # Retrieve text\n",
    "    q_text = questions.get(int(qid), questions.get(qid, \"[Question not found]\"))\n",
    "\n",
    "    # answer label lookup tries both str & int keys\n",
    "    a_label = (\n",
    "        answers.get((qid, pos)) or\n",
    "        answers.get((int(qid), pos))\n",
    "    )\n",
    "\n",
    "    # if still missing and this is one of our \"Other\" buckets\n",
    "    if a_label is None and 'merge_log' in globals() and head in merge_log:\n",
    "        a_label = \"Other\"\n",
    "\n",
    "    rows.append({\n",
    "        \"col_name\":      col,\n",
    "        \"QuestionID\":    qid,\n",
    "        \"AnswerPos\":     pos,\n",
    "        \"QuestionText\":  q_text,\n",
    "        \"AnswerLabel\":   a_label,\n",
    "    })\n",
    "\n",
    "mapping_df = pd.DataFrame(rows)\n",
    "\n",
    "# --- write to Excel ---------------------------------------------------------\n",
    "\n",
    "out_path = Path(\"data_processed/survey_dataframe.xlsx\")\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    mapping_df.to_excel(writer, sheet_name=\"mapping\", index=False)\n",
    "\n",
    "print(f\"Mapping sheet written to {out_path} (sheet name: 'mapping')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e37ee6f",
   "metadata": {},
   "source": [
    "### Filter Social Media Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6c83efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #15a\n",
    "# # Filtering the specific social media question to a sperate dataframe to analyse closer\n",
    "\n",
    "\n",
    "# candidates = [\n",
    "#     (qid, txt) for qid, txt in questions.items()\n",
    "#     if \"social media\" in txt.lower()\n",
    "# ]\n",
    "\n",
    "# print(f\"Found {len(candidates)} questions containing 'social media':\\n\")\n",
    "# for qid, txt in candidates:\n",
    "#     print(f\"{qid}: {txt[:120]}{'...' if len(txt) > 120 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ded87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 15b\n",
    "# # isolate the columns & build the dataframe\n",
    "\n",
    "\n",
    "# social_qids = {str(qid) for qid, _ in candidates}   # use ALL discovered qids\n",
    "# print(\"Using QuestionIDs:\", social_qids)\n",
    "\n",
    "# def belongs(col):\n",
    "#     head = col.split(\":\", 1)[0]\n",
    "#     qid  = head.split(\"_\", 1)[0]\n",
    "#     return qid in social_qids\n",
    "\n",
    "# sm_cols  = [\"SurveyInstanceID\"] + [c for c in pivot_pretty.columns if belongs(c)]\n",
    "# social_df = pivot_pretty[sm_cols].copy()\n",
    "\n",
    "# print(\"social_df shape:\", social_df.shape)\n",
    "# social_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90fa2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 15c\n",
    "# # Write to excell, analyse data\n",
    "\n",
    "# from pathlib import Path\n",
    "# import pandas as pd\n",
    "\n",
    "# data_only = social_df[social_df['SurveyInstanceID'] != 'Pct_1s']\n",
    "# n_rows    = len(data_only)\n",
    "\n",
    "# rows = []\n",
    "# for col in social_df.columns:\n",
    "#     if col == \"SurveyInstanceID\":\n",
    "#         continue\n",
    "#     head = col.split(\":\", 1)[0]\n",
    "#     parts = head.split(\"_\", 1)\n",
    "#     qid = parts[0]\n",
    "#     pos = int(parts[1]) if len(parts) > 1 and parts[1].isdigit() else None\n",
    "\n",
    "#     count = int(data_only[col].sum())\n",
    "#     pct   = round(count / n_rows * 100, 2)\n",
    "\n",
    "#     q_txt = questions.get(int(qid), questions.get(qid, \"[Question not found]\"))\n",
    "#     a_txt = (\n",
    "#         answers.get((qid, pos)) or\n",
    "#         answers.get((int(qid), pos)) or\n",
    "#         (\"Other\" if head in merge_log else \"[Answer label not found]\")\n",
    "#     )\n",
    "\n",
    "#     rows.append({\n",
    "#         \"QuestionID\":  qid,\n",
    "#         \"AnswerPos\":   pos,\n",
    "#         \"Question\":    q_txt,\n",
    "#         \"AnswerLabel\": a_txt,\n",
    "#         \"count_1s\":    count,\n",
    "#         \"pct_1s\":      pct,\n",
    "#         \"col_name\":    col,\n",
    "#     })\n",
    "\n",
    "# analysis_df = pd.DataFrame(rows)\n",
    "\n",
    "# out_path = Path(\"data_processed/social_media_dataframe.xlsx\")\n",
    "# with pd.ExcelWriter(out_path, engine=\"openpyxl\") as w:\n",
    "#     social_df.to_excel(w, sheet_name=\"data\",     index=False)\n",
    "#     analysis_df.to_excel(w, sheet_name=\"analysis\", index=False)\n",
    "\n",
    "# print(f\"Saved Social‑Media workbook ➜ {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37336d27",
   "metadata": {},
   "source": [
    "### Scan for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05f25cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 18  ── Data-quality scan\n",
    "# from collections import Counter          # ← add this\n",
    "\n",
    "# report = {}\n",
    "\n",
    "# # 1. duplicate SurveyInstanceID rows\n",
    "# dup_ids = pivot_pretty['SurveyInstanceID'].value_counts()\n",
    "# report['duplicate_ids'] = dup_ids[dup_ids > 1].index.tolist()\n",
    "\n",
    "# # 2. columns that are entirely zero (no one selected them)\n",
    "# binary_cols = [c for c in pivot_pretty.columns if c != 'SurveyInstanceID']\n",
    "# all_zero    = [c for c in binary_cols if pivot_pretty[c].dropna().sum() == 0]\n",
    "# report['all_zero_cols'] = all_zero\n",
    "\n",
    "# # 3. completely blank rows (no answers ticked at all)\n",
    "# blank_rows = (pivot_pretty[binary_cols].sum(axis=1) == 0).sum()\n",
    "# report['blank_rows'] = int(blank_rows)\n",
    "\n",
    "# # 4. single-choice questions with >1 option ticked in a row\n",
    "# violations = Counter()\n",
    "# for qid in {c.split('_', 1)[0] for c in binary_cols}:\n",
    "#     q_cols = [c for c in binary_cols if c.startswith(f'{qid}_')]\n",
    "#     if len(q_cols) <= 1:          # multi-select or scalar — ignore\n",
    "#         continue\n",
    "#     too_many = (pivot_pretty[q_cols].sum(axis=1) > 1).sum()\n",
    "#     if too_many:\n",
    "#         violations[qid] = int(too_many)\n",
    "# report['single_choice_violations'] = dict(violations)\n",
    "\n",
    "# # Show the report\n",
    "# print(\"=== Data-quality report ===\")\n",
    "# for k, v in report.items():\n",
    "#     print(f\"{k}: {v if v else 'OK'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "341bb0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 19 — Response‑rate heat‑map  ( % of respondents selecting each answer )\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # ── 1.  Work on real‑response rows only ────────────────────────────────────────\n",
    "# data_df = pivot_pretty[pivot_pretty['SurveyInstanceID'] != 'Pct_1s']\n",
    "\n",
    "# binary_cols = [c for c in data_df.columns if c != \"SurveyInstanceID\"]\n",
    "\n",
    "# def split_col(col):\n",
    "#     \"\"\"\"\"\"Return (qid, pos_int) from a column name like '360187_3: …'.\"\"\"\"\"\"\"\"\n",
    "#     head = col.split(\":\", 1)[0]          # strip pretty suffix if present\n",
    "#     if \"_\" in head:\n",
    "#         qid, pos = head.split(\"_\", 1)\n",
    "#         try:\n",
    "#             pos = int(pos)\n",
    "#         except ValueError:\n",
    "#             pos = 1                      # safety fallback\n",
    "#     else:\n",
    "#         qid, pos = head, 1\n",
    "#     return qid, pos\n",
    "\n",
    "# records = []\n",
    "# for col in binary_cols:\n",
    "#     qid, pos = split_col(col)\n",
    "#     pct = round(data_df[col].mean() * 100, 2)   # % of respondents who marked 1\n",
    "#     records.append((qid, pos, pct))\n",
    "\n",
    "# heat_df = (\n",
    "#     pd.DataFrame(records, columns=[\"qid\", \"pos\", \"pct\"])\n",
    "#       .pivot(index=\"qid\", columns=\"pos\", values=\"pct\")\n",
    "#       .sort_index()\n",
    "#       .fillna(0)\n",
    "# )\n",
    "\n",
    "# # ── 2.  Plot heat‑map (single plot, no custom colors) ─────────────────────────\n",
    "# plt.figure(figsize=(12, max(4, heat_df.shape[0] * 0.25)))\n",
    "# plt.imshow(heat_df.values, aspect=\"auto\")\n",
    "# plt.colorbar(label=\"% respondents\")\n",
    "# plt.xticks(np.arange(len(heat_df.columns)), heat_df.columns)\n",
    "# plt.yticks(np.arange(len(heat_df.index)), heat_df.index)\n",
    "# plt.title(\"Response‑rate heat‑map\")\n",
    "# plt.xlabel(\"Answer position\")\n",
    "# plt.ylabel(\"QuestionID\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e09175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === QA CHECK CELL (place at the end) =========================================\n",
    "# # Choose a QuestionID and verify the rare-answer merging.\n",
    "# # - Builds a summary table for that question with count of 1s and % of 1s\n",
    "# # - Shows which columns are auto-created \"Other\" buckets\n",
    "# # - Lists all datapoints (SurveyInstanceID) for columns under 5%\n",
    "# # - Checks that listed datapoints match the summarized counts\n",
    "# #\n",
    "# # Set qid_selected to a specific ID (e.g., \"360187\") or leave as None to auto-pick.\n",
    "\n",
    "# THRESHOLD_PCT = 5.0        # \"under 5%\" threshold\n",
    "# qid_selected = None        # e.g. \"360187\" or 360187\n",
    "\n",
    "# def _extract_head(col: str) -> str:\n",
    "#     # part before any pretty suffix like ': Label text'\n",
    "#     return col.split(\":\", 1)[0]\n",
    "\n",
    "# def _split_col(head: str):\n",
    "#     # returns (qid_str, pos_int) ; pos=1 for single-choice style heads\n",
    "#     if \"_\" in head:\n",
    "#         qid_str, pos_str = head.split(\"_\", 1)\n",
    "#         pos_str = re.sub(r\"\\D+\", \"\", pos_str) or \"1\"\n",
    "#         try:\n",
    "#             pos = int(pos_str)\n",
    "#         except ValueError:\n",
    "#             pos = 1\n",
    "#         return qid_str, pos\n",
    "#     return head, 1\n",
    "\n",
    "# def _label_for(qid_str: str, pos: int):\n",
    "#     # Fetch human-readable texts from `questions` and `answers` where available\n",
    "#     q_text = \"[Question text not found]\"\n",
    "#     a_label = None\n",
    "\n",
    "#     # Question text\n",
    "#     if \"questions\" in globals():\n",
    "#         try:\n",
    "#             qid_int = int(qid_str)\n",
    "#         except ValueError:\n",
    "#             qid_int = None\n",
    "#         if qid_int is not None:\n",
    "#             q_text = questions.get(qid_int, questions.get(qid_str, q_text))\n",
    "#         else:\n",
    "#             q_text = questions.get(qid_str, q_text)\n",
    "\n",
    "#     # Answer label\n",
    "#     if \"answers\" in globals():\n",
    "#         try:\n",
    "#             qid_int = int(qid_str)\n",
    "#         except ValueError:\n",
    "#             qid_int = None\n",
    "#         if qid_int is not None:\n",
    "#             a_label = answers.get((qid_int, pos), answers.get((qid_str, pos)))\n",
    "#         else:\n",
    "#             a_label = answers.get((qid_str, pos))\n",
    "\n",
    "#     # If still missing and this head was created as an \"Other\" bucket\n",
    "#     if a_label is None and \"merge_log\" in globals():\n",
    "#         head = f\"{qid_str}_{pos}\"\n",
    "#         if head in merge_log:\n",
    "#             a_label = \"Other\"\n",
    "\n",
    "#     if a_label is None:\n",
    "#         a_label = \"[Answer label not found]\"\n",
    "#     return q_text, a_label\n",
    "\n",
    "# # ---- guards & base frame -----------------------------------------------------\n",
    "# if \"pivot_pretty\" not in globals():\n",
    "#     raise RuntimeError(\"pivot_pretty is not defined. Run the cells that build it first.\")\n",
    "\n",
    "# # Remove the summary row if present\n",
    "# if \"SurveyInstanceID\" in pivot_pretty.columns:\n",
    "#     data_df = pivot_pretty.loc[~pivot_pretty[\"SurveyInstanceID\"].astype(str).eq(\"Pct_1s\")].copy()\n",
    "# else:\n",
    "#     data_df = pivot_pretty.copy()\n",
    "\n",
    "# n_rows = len(data_df)\n",
    "# non_binary_cols = [\"SurveyInstanceID\"] if \"SurveyInstanceID\" in data_df.columns else []\n",
    "# data_cols = [c for c in data_df.columns if c not in non_binary_cols]\n",
    "\n",
    "# # Build map of qid -> count of columns to help pick a default\n",
    "# qid_counts = {}\n",
    "# for col in data_cols:\n",
    "#     head = _extract_head(col)\n",
    "#     qid_str, _ = _split_col(head)\n",
    "#     qid_counts[qid_str] = qid_counts.get(qid_str, 0) + 1\n",
    "\n",
    "# if qid_selected is None:\n",
    "#     if not qid_counts:\n",
    "#         raise RuntimeError(\"No data columns found to infer QuestionIDs.\")\n",
    "#     qid_selected = max(qid_counts.items(), key=lambda kv: kv[1])[0]\n",
    "# qid_selected = str(qid_selected)\n",
    "\n",
    "# # Collect columns for the chosen question\n",
    "# rows_meta = []\n",
    "# for col in data_cols:\n",
    "#     head = _extract_head(col)\n",
    "#     qid_str, pos = _split_col(head)\n",
    "#     if qid_str == qid_selected:\n",
    "#         is_other = (\"merge_log\" in globals()) and (head in merge_log)\n",
    "#         rows_meta.append((col, head, pos, is_other))\n",
    "\n",
    "# if not rows_meta:\n",
    "#     raise RuntimeError(f\"No columns found for QuestionID {qid_selected}. \"\n",
    "#                        f\"Available QuestionIDs: {sorted(qid_counts.keys())[:20]}{' …' if len(qid_counts)>20 else ''}\")\n",
    "\n",
    "# # Order: originals first, then new \"Other\" columns\n",
    "# rows_meta.sort(key=lambda t: (t[3], t[2]))  # (is_other, AnswerPos)\n",
    "\n",
    "# # Build summary table\n",
    "# summary_rows = []\n",
    "# for col, head, pos, is_other in rows_meta:\n",
    "#     q_text, a_label = _label_for(qid_selected, pos)\n",
    "#     count_1s = int(data_df[col].astype(int).sum())\n",
    "#     pct_1s = round((count_1s / n_rows) * 100, 2) if n_rows else 0.0\n",
    "#     summary_rows.append({\n",
    "#         \"QuestionID\": qid_selected,\n",
    "#         \"QuestionText\": q_text,\n",
    "#         \"col_name\": col,\n",
    "#         \"head\": head,\n",
    "#         \"AnswerPos\": pos,\n",
    "#         \"is_other\": bool(is_other),\n",
    "#         \"AnswerLabel\": a_label,\n",
    "#         \"count_1s\": count_1s,\n",
    "#         \"pct_1s\": pct_1s,\n",
    "#         \"n_rows\": n_rows,\n",
    "#     })\n",
    "\n",
    "# summary_q = pd.DataFrame(summary_rows)\n",
    "\n",
    "# print(f\"Chosen QuestionID: {qid_selected}\")\n",
    "# if \"questions\" in globals():\n",
    "#     try:\n",
    "#         qid_int = int(qid_selected)\n",
    "#     except ValueError:\n",
    "#         qid_int = None\n",
    "#     q_text_print = questions.get(qid_int, questions.get(qid_selected)) if qid_int is not None else questions.get(qid_selected)\n",
    "#     if q_text_print:\n",
    "#         print(\"Question text:\", q_text_print)\n",
    "\n",
    "# display(summary_q)\n",
    "\n",
    "# # Columns under the threshold\n",
    "# low_q = summary_q[summary_q[\"pct_1s\"] < THRESHOLD_PCT].copy()\n",
    "# print(f\"\\nColumns under {THRESHOLD_PCT}%: {len(low_q)}\")\n",
    "# display(low_q[[\"col_name\", \"AnswerPos\", \"is_other\", \"AnswerLabel\", \"count_1s\", \"pct_1s\"]])\n",
    "\n",
    "# # Show datapoints (SurveyInstanceID values) for each low-frequency column\n",
    "# records = []\n",
    "# for _, r in low_q.iterrows():\n",
    "#     col = r[\"col_name\"]\n",
    "#     if \"SurveyInstanceID\" in data_df.columns:\n",
    "#         ids = data_df.loc[data_df[col] == 1, \"SurveyInstanceID\"].astype(str).tolist()\n",
    "#     else:\n",
    "#         ids = data_df.index[data_df[col] == 1].astype(str).tolist()\n",
    "\n",
    "#     records.append({\n",
    "#         \"col_name\": col,\n",
    "#         \"observed_count\": len(ids),\n",
    "#         \"summary_count_1s\": int(r[\"count_1s\"]),\n",
    "#         \"expected_from_pct\": round(r[\"pct_1s\"] * r[\"n_rows\"] / 100.0, 2),\n",
    "#         \"SurveyInstanceIDs\": ids,\n",
    "#     })\n",
    "\n",
    "# low_points = pd.DataFrame(records)\n",
    "# print(\"\\nDatapoints for columns under threshold:\")\n",
    "# display(low_points)\n",
    "\n",
    "# # Consistency check\n",
    "# mismatches = low_points[low_points[\"observed_count\"] != low_points[\"summary_count_1s\"]]\n",
    "# if mismatches.empty:\n",
    "#     print(\"✅ All low-frequency columns match between listed datapoints and summarized counts.\")\n",
    "# else:\n",
    "#     print(\"⚠️ Mismatch detected. Review the following rows:\")\n",
    "#     display(mismatches)\n",
    "# # =============================================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
